{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjli01/PySpark-Notes/blob/main/13_Explode%2C_Arrays%2C_Maps%2C_Structs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Complex Data Types: Arrays, Maps, Structs\n",
        "\n",
        "Spark DataFrames are powerful for semi-structured and nested data common in formats like JSON or Parquet.\n",
        "\n",
        "### Creating Complex Types\n",
        "\n",
        "*   `array()`: Creates an array column.\n",
        "*   `map()`: Creates a map column.\n",
        "*   `struct()`: Creates a struct column (similar to a row or object within a column).\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "_1PZBnqKJih3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import array, map_from_entries, struct, col, lit\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, MapType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ComplexTypes\").getOrCreate()\n",
        "\n",
        "# Manual schema definition for clarity\n",
        "schema = StructType([\n",
        "    StructField(\"Name\", StringType(), True),\n",
        "    StructField(\"Scores\", ArrayType(IntegerType()), True),\n",
        "    StructField(\"AddressMap\", MapType(StringType(), StringType()), True), # Map from list of tuples\n",
        "    StructField(\"Vehicle\", StructType([\n",
        "        StructField(\"Color\", StringType(), True),\n",
        "        StructField(\"Type\", StringType(), True)\n",
        "    ]), True)\n",
        "])\n",
        "\n",
        "data = [\n",
        "    (\"Alice\", [10, 20], {\"city\": \"NY\", \"zip\": \"10001\"}, (\"Red\", \"Car\")),\n",
        "    (\"Bob\", [30], {\"city\": \"LD\"}, (\"Blue\", \"Bike\"))\n",
        "]\n",
        "columns = [\"Name\", \"Scores\", \"AddressMap\", \"Vehicle\"]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=schema)\n",
        "print(\"Original DataFrame with complex types:\")\n",
        "df.show(truncate=False)\n",
        "df.printSchema()\n",
        "\n",
        "# Another way to create complex types using functions in select\n",
        "df_created = spark.createDataFrame([\n",
        "    (1, \"Alice\"),\n",
        "    (2, \"Bob\")\n",
        "]).select(\n",
        "    col(\"_1\").alias(\"ID\"),\n",
        "    col(\"_2\").alias(\"Name\"),\n",
        "    array(lit(\"Apple\"), lit(\"Banana\")).alias(\"Fruits\"), # ArrayType\n",
        "    map_from_entries(array(struct(lit(\"key1\"), lit(\"value1\")), struct(lit(\"key2\"), lit(\"value2\")))).alias(\"Properties\"), # MapType\n",
        "    struct(lit(\"Main St\").alias(\"Street\"), lit(\"Anytown\").alias(\"City\")).alias(\"Location\") # StructType\n",
        ")\n",
        "print(\"\\nDataFrame created with functions:\")\n",
        "df_created.show(truncate=False)\n",
        "df_created.printSchema()\n",
        "\n",
        "# spark.stop() # Uncomment to stop SparkSession"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIE0tepcmJTL",
        "outputId": "51992198-ea67-423c-ab71-07bba3df27bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame with complex types:\n",
            "+-----+--------+--------------------------+------------+\n",
            "|Name |Scores  |AddressMap                |Vehicle     |\n",
            "+-----+--------+--------------------------+------------+\n",
            "|Alice|[10, 20]|{zip -> 10001, city -> NY}|{Red, Car}  |\n",
            "|Bob  |[30]    |{city -> LD}              |{Blue, Bike}|\n",
            "+-----+--------+--------------------------+------------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Scores: array (nullable = true)\n",
            " |    |-- element: integer (containsNull = true)\n",
            " |-- AddressMap: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            " |-- Vehicle: struct (nullable = true)\n",
            " |    |-- Color: string (nullable = true)\n",
            " |    |-- Type: string (nullable = true)\n",
            "\n",
            "\n",
            "DataFrame created with functions:\n",
            "+---+-----+---------------+--------------------------------+------------------+\n",
            "|ID |Name |Fruits         |Properties                      |Location          |\n",
            "+---+-----+---------------+--------------------------------+------------------+\n",
            "|1  |Alice|[Apple, Banana]|{key1 -> value1, key2 -> value2}|{Main St, Anytown}|\n",
            "|2  |Bob  |[Apple, Banana]|{key1 -> value1, key2 -> value2}|{Main St, Anytown}|\n",
            "+---+-----+---------------+--------------------------------+------------------+\n",
            "\n",
            "root\n",
            " |-- ID: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Fruits: array (nullable = false)\n",
            " |    |-- element: string (containsNull = false)\n",
            " |-- Properties: map (nullable = false)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = false)\n",
            " |-- Location: struct (nullable = false)\n",
            " |    |-- Street: string (nullable = false)\n",
            " |    |-- City: string (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploding Arrays & Maps into Rows: `explode()` and `explode_outer()`\n",
        "\n",
        "`explode()` transforms an array or map column into individual rows for each element/key-value pair.\n",
        "\n",
        "*   **`explode()`**: If an array/map column has N elements, it generates N rows for that array, duplicating other column values.\n",
        "    *   **Behavior with null/empty:** Drops rows where the array/map column is `null` or empty.\n",
        "*   **`explode_outer()` (Spark 2.4+)**: Similar to `explode()`, but it keeps rows even if the array/map column is `null` or empty. It will produce a `null` for the exploded column in these cases, similar to a `LEFT JOIN`.\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "4AOWYb-YXZ85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tvx04HbD_Ej",
        "outputId": "a2daf02c-7097-4565-f70f-ce19e614048f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "+-------+--------------------------+\n",
            "|Name   |Hobbies                   |\n",
            "+-------+--------------------------+\n",
            "|Alice  |[reading, hiking, cooking]|\n",
            "|Bob    |[coding, gaming]          |\n",
            "|Charlie|[]                        |\n",
            "+-------+--------------------------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Hobbies: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "\n",
            "DataFrame after exploding 'Hobbies' (drops empty/null):\n",
            "+-----+--------------------+-------+\n",
            "| Name|             Hobbies|  Hobby|\n",
            "+-----+--------------------+-------+\n",
            "|Alice|[reading, hiking,...|reading|\n",
            "|Alice|[reading, hiking,...| hiking|\n",
            "|Alice|[reading, hiking,...|cooking|\n",
            "|  Bob|    [coding, gaming]| coding|\n",
            "|  Bob|    [coding, gaming]| gaming|\n",
            "+-----+--------------------+-------+\n",
            "\n",
            "\n",
            "DataFrame with null/empty arrays:\n",
            "+-------+-----------------+\n",
            "|Name   |Hobbies          |\n",
            "+-------+-----------------+\n",
            "|Alice  |[reading, hiking]|\n",
            "|Bob    |NULL             |\n",
            "|Charlie|[]               |\n",
            "+-------+-----------------+\n",
            "\n",
            "\n",
            "DataFrame after exploding with null/empty arrays (using explode - rows dropped):\n",
            "+-----+-----------------+-------+\n",
            "| Name|          Hobbies|  Hobby|\n",
            "+-----+-----------------+-------+\n",
            "|Alice|[reading, hiking]|reading|\n",
            "|Alice|[reading, hiking]| hiking|\n",
            "+-----+-----------------+-------+\n",
            "\n",
            "\n",
            "DataFrame after exploding with explode_outer (keeps rows):\n",
            "+-------+-----------------+-------+\n",
            "|   Name|          Hobbies|  Hobby|\n",
            "+-------+-----------------+-------+\n",
            "|  Alice|[reading, hiking]|reading|\n",
            "|  Alice|[reading, hiking]| hiking|\n",
            "|    Bob|             NULL|   NULL|\n",
            "|Charlie|               []|   NULL|\n",
            "+-------+-----------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode, explode_outer, col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ExplodeArrays\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"Alice\", [\"reading\", \"hiking\", \"cooking\"]),\n",
        "    (\"Bob\", [\"coding\", \"gaming\"]),\n",
        "    (\"Charlie\", []) # Empty array\n",
        "]\n",
        "columns = [\"Name\", \"Hobbies\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "print(\"Original DataFrame:\")\n",
        "df.show(truncate=False)\n",
        "df.printSchema()\n",
        "\n",
        "# Explode the 'Hobbies' array column using explode()\n",
        "print(\"\\nDataFrame after exploding 'Hobbies' (drops empty/null):\")\n",
        "df.withColumn(\"Hobby\", explode(col(\"Hobbies\"))).show()\n",
        "\n",
        "# What happens if a column is null or empty with explode()?\n",
        "data_with_null_array = [\n",
        "    (\"Alice\", [\"reading\", \"hiking\"]),\n",
        "    (\"Bob\", None), # Null array\n",
        "    (\"Charlie\", []) # Empty array\n",
        "]\n",
        "df_null_array = spark.createDataFrame(data_with_null_array, columns)\n",
        "print(\"\\nDataFrame with null/empty arrays:\")\n",
        "df_null_array.show(truncate=False)\n",
        "\n",
        "# When exploding a null or empty array, the row for that record is dropped by default.\n",
        "print(\"\\nDataFrame after exploding with null/empty arrays (using explode - rows dropped):\")\n",
        "df_null_array.withColumn(\"Hobby\", explode(col(\"Hobbies\"))).show()\n",
        "\n",
        "# To keep rows with null/empty arrays, use 'explode_outer` (Spark 2.4+)\n",
        "print(\"\\nDataFrame after exploding with explode_outer (keeps rows):\")\n",
        "df_null_array.withColumn(\"Hobby\", explode_outer(col(\"Hobbies\"))).show()\n",
        "\n",
        "# spark.stop() # Uncomment to stop SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flattening Nested Schemas\n",
        "\n",
        "Flattening transforms nested structures (StructType, or ArrayType of StructType) into a flatter structure with top-level columns, making data easier to query.\n",
        "\n",
        "*   **For `StructType`:** Access elements using dot notation (`parent.child`) and select them as new columns.\n",
        "*   **For `ArrayType` of `StructType`:** First, use `explode()` to create individual rows for each struct in the array, then access elements using dot notation.\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "BZrLg52_XaX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode\n",
        "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"FlatteningSchemas\").getOrCreate()\n",
        "\n",
        "# --- Flattening StructType ---\n",
        "data_struct = [\n",
        "    (\"Alice\", {\"street\": \"Main St\", \"city\": \"NY\"}),\n",
        "    (\"Bob\", {\"street\": \"Elm St\", \"city\": \"LD\"})\n",
        "]\n",
        "schema_struct = StructType([\n",
        "    StructField(\"Name\", StringType(), True),\n",
        "    StructField(\"Address\", StructType([\n",
        "        StructField(\"street\", StringType(), True),\n",
        "        StructField(\"city\", StringType(), True)\n",
        "    ]), True)\n",
        "])\n",
        "df_struct = spark.createDataFrame(data_struct, schema_struct)\n",
        "print(\"Original DataFrame with StructType:\")\n",
        "df_struct.show(truncate=False)\n",
        "df_struct.printSchema()\n",
        "\n",
        "print(\"\\nFlattening StructType:\")\n",
        "df_flattened_struct = df_struct.select(\n",
        "    col(\"Name\"),\n",
        "    col(\"Address.street\").alias(\"Street\"),\n",
        "    col(\"Address.city\").alias(\"City\")\n",
        ")\n",
        "df_flattened_struct.show(truncate=False)\n",
        "df_flattened_struct.printSchema()\n",
        "\n",
        "# --- Flattening ArrayType of StructType ---\n",
        "data_array_struct = [\n",
        "    (\"ProductA\", [{\"feature_name\": \"Color\", \"value\": \"Red\"}, {\"feature_name\": \"Size\", \"value\": \"M\"}]),\n",
        "    (\"ProductB\", [{\"feature_name\": \"Weight\", \"value\": \"1kg\"}])\n",
        "]\n",
        "schema_array_struct = StructType([\n",
        "    StructField(\"Product\", StringType(), True),\n",
        "    StructField(\"Features\", ArrayType(StructType([\n",
        "        StructField(\"feature_name\", StringType(), True),\n",
        "        StructField(\"value\", StringType(), True)\n",
        "    ])), True)\n",
        "])\n",
        "df_array_struct = spark.createDataFrame(data_array_struct, schema_array_struct)\n",
        "print(\"\\nOriginal DataFrame with ArrayType of StructType:\")\n",
        "df_array_struct.show(truncate=False)\n",
        "df_array_struct.printSchema()\n",
        "\n",
        "print(\"\\nFlattening ArrayType of StructType (requires explode first):\")\n",
        "df_flattened_array_struct = df_array_struct.withColumn(\"exploded_features\", explode(col(\"Features\"))) \\\n",
        "    .select(\n",
        "        col(\"Product\"),\n",
        "        col(\"exploded_features.feature_name\"),\n",
        "        col(\"exploded_features.value\")\n",
        "    )\n",
        "df_flattened_array_struct.show(truncate=False)\n",
        "df_flattened_array_struct.printSchema()\n",
        "\n",
        "# spark.stop() # Uncomment to stop SparkSession"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN-EdW4tXasc",
        "outputId": "1f05aa6b-c2cd-424c-ef17-80c75493b9e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame with StructType:\n",
            "+-----+-------------+\n",
            "|Name |Address      |\n",
            "+-----+-------------+\n",
            "|Alice|{Main St, NY}|\n",
            "|Bob  |{Elm St, LD} |\n",
            "+-----+-------------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Address: struct (nullable = true)\n",
            " |    |-- street: string (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            "\n",
            "\n",
            "Flattening StructType:\n",
            "+-----+-------+----+\n",
            "|Name |Street |City|\n",
            "+-----+-------+----+\n",
            "|Alice|Main St|NY  |\n",
            "|Bob  |Elm St |LD  |\n",
            "+-----+-------+----+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Street: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            "\n",
            "\n",
            "Original DataFrame with ArrayType of StructType:\n",
            "+--------+-------------------------+\n",
            "|Product |Features                 |\n",
            "+--------+-------------------------+\n",
            "|ProductA|[{Color, Red}, {Size, M}]|\n",
            "|ProductB|[{Weight, 1kg}]          |\n",
            "+--------+-------------------------+\n",
            "\n",
            "root\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Features: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- feature_name: string (nullable = true)\n",
            " |    |    |-- value: string (nullable = true)\n",
            "\n",
            "\n",
            "Flattening ArrayType of StructType (requires explode first):\n",
            "+--------+------------+-----+\n",
            "|Product |feature_name|value|\n",
            "+--------+------------+-----+\n",
            "|ProductA|Color       |Red  |\n",
            "|ProductA|Size        |M    |\n",
            "|ProductB|Weight      |1kg  |\n",
            "+--------+------------+-----+\n",
            "\n",
            "root\n",
            " |-- Product: string (nullable = true)\n",
            " |-- feature_name: string (nullable = true)\n",
            " |-- value: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing Fields\n",
        "\n",
        "*   **`StructType`:** Use dot notation: `col(\"parent_struct.child_field\")`.\n",
        "*   **`MapType`:**\n",
        "    *   `col(\"map_col\")[\"key\"]`: Direct access.\n",
        "    *   `element_at(col(\"map_col\"), \"key\")`: More robust, handles missing keys gracefully.\n",
        "*   **`ArrayType`:**\n",
        "    *   `col(\"array_col\")[index]`: Direct element access (use with caution, as index might be out of bounds).\n",
        "    *   `explode()`: For iterating over all elements as individual rows.\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "XiklAH4iXbGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode, element_at\n",
        "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, MapType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AccessingNestedFields\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"Alice\", {\"street\": \"Main St\", \"city\": \"NY\"}, [\"A\", \"B\"], {\"email\": \"a@ex.com\", \"phone\": \"111\"}),\n",
        "    (\"Bob\", {\"street\": \"Elm St\", \"city\": \"LD\"}, [\"C\"], {\"email\": \"b@ex.com\"})\n",
        "]\n",
        "schema = StructType([\n",
        "    StructField(\"Name\", StringType(), True),\n",
        "    StructField(\"Address\", StructType([\n",
        "        StructField(\"street\", StringType(), True),\n",
        "        StructField(\"city\", StringType(), True)\n",
        "    ]), True),\n",
        "    StructField(\"Grades\", ArrayType(StringType()), True),\n",
        "    StructField(\"Contact\", MapType(StringType(), StringType()), True)\n",
        "])\n",
        "df = spark.createDataFrame(data, schema=schema)\n",
        "print(\"Original DataFrame:\")\n",
        "df.show(truncate=False)\n",
        "df.printSchema()\n",
        "\n",
        "# Accessing StructType fields\n",
        "print(\"\\nAccessing StructType fields:\")\n",
        "df.select(\n",
        "    col(\"Name\"),\n",
        "    col(\"Address.street\").alias(\"Street\"),\n",
        "    col(\"Address.city\").alias(\"City\")\n",
        ").show()\n",
        "\n",
        "# Accessing MapType fields\n",
        "print(\"\\nAccessing MapType fields:\")\n",
        "df.select(\n",
        "    col(\"Name\"),\n",
        "    col(\"Contact.email\").alias(\"Email\"), # Using dot notation (common for maps in some contexts)\n",
        "    element_at(col(\"Contact\"), \"phone\").alias(\"Phone\") # More robust way for map keys\n",
        ").show()\n",
        "\n",
        "# Accessing ArrayType fields by index\n",
        "print(\"\\nAccessing ArrayType fields by index:\")\n",
        "df.select(\n",
        "    col(\"Name\"),\n",
        "    col(\"Grades\")[0].alias(\"FirstGrade\") # Accessing first element\n",
        ").show()\n",
        "\n",
        "# Iterating ArrayType fields using explode\n",
        "print(\"\\nAccessing ArrayType fields using explode:\")\n",
        "df.withColumn(\"Grade\", explode(col(\"Grades\"))).show()\n",
        "\n",
        "# spark.stop() # Uncomment to stop SparkSession"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzLFl304Xbc4",
        "outputId": "c50687b1-a999-436a-a2d3-aa681eaacdb7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "+-----+-------------+------+---------------------------------+\n",
            "|Name |Address      |Grades|Contact                          |\n",
            "+-----+-------------+------+---------------------------------+\n",
            "|Alice|{Main St, NY}|[A, B]|{phone -> 111, email -> a@ex.com}|\n",
            "|Bob  |{Elm St, LD} |[C]   |{email -> b@ex.com}              |\n",
            "+-----+-------------+------+---------------------------------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Address: struct (nullable = true)\n",
            " |    |-- street: string (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |-- Grades: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- Contact: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "\n",
            "Accessing StructType fields:\n",
            "+-----+-------+----+\n",
            "| Name| Street|City|\n",
            "+-----+-------+----+\n",
            "|Alice|Main St|  NY|\n",
            "|  Bob| Elm St|  LD|\n",
            "+-----+-------+----+\n",
            "\n",
            "\n",
            "Accessing MapType fields:\n",
            "+-----+--------+-----+\n",
            "| Name|   Email|Phone|\n",
            "+-----+--------+-----+\n",
            "|Alice|a@ex.com|  111|\n",
            "|  Bob|b@ex.com| NULL|\n",
            "+-----+--------+-----+\n",
            "\n",
            "\n",
            "Accessing ArrayType fields by index:\n",
            "+-----+----------+\n",
            "| Name|FirstGrade|\n",
            "+-----+----------+\n",
            "|Alice|         A|\n",
            "|  Bob|         C|\n",
            "+-----+----------+\n",
            "\n",
            "\n",
            "Accessing ArrayType fields using explode:\n",
            "+-----+-------------+------+--------------------+-----+\n",
            "| Name|      Address|Grades|             Contact|Grade|\n",
            "+-----+-------------+------+--------------------+-----+\n",
            "|Alice|{Main St, NY}|[A, B]|{phone -> 111, em...|    A|\n",
            "|Alice|{Main St, NY}|[A, B]|{phone -> 111, em...|    B|\n",
            "|  Bob| {Elm St, LD}|   [C]| {email -> b@ex.com}|    C|\n",
            "+-----+-------------+------+--------------------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}