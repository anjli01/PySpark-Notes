{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjli01/PySpark-Notes/blob/main/05_Column_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column Operations\n",
        "\n",
        "Column operations are fundamental for data cleaning, transformation, and feature engineering in PySpark. They allow you to manipulate, create, and modify data within DataFrame columns efficiently.\n",
        "\n",
        "### Key Functions for Column Expressions\n",
        "\n",
        "PySpark provides essential functions in `pyspark.sql.functions` to construct powerful expressions:\n",
        "\n",
        "| Function           | Description                                                                                                                                                                                                                                                         | Interview Tip                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
        "| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| `col(column_name)` | **References a column by its name.** Safest way, especially with names conflicting with keywords or containing special characters.                                                                                                                                 | Always prefer `col()` for referencing existing columns over string literals (e.g., `df[\"column_name\"]`) as it's more robust and readable, especially when combining with other functions.                                                                                                                                                                                                                             |\n",
        "| `lit(value)`       | **Creates a literal column with the given value.** Useful for adding constant values to a DataFrame.                                                                                                                                                                | Use `lit()` when you need to introduce a fixed value into your DataFrame, such as a default category, a timestamp of processing, or a placeholder.                                                                                                                                                                                                                                                             |\n",
        "| `expr(sql_expression_string)` | **Allows you to use SQL expressions directly within DataFrame operations.** Very powerful for complex logic not easily expressible with other PySpark functions.                                                                                                                               | `expr()` is a wildcard for complex scenarios. If you find a SQL expression that does exactly what you need, `expr()` is often the quickest way to integrate it, bridging the gap between SQL and DataFrame API. Be cautious with readability for extremely complex SQL strings.                                                                                                                             |\n",
        "| `when(condition, value)` | **Implements conditional logic** (similar to `IF` or `CASE` in SQL). If `condition` is true, it returns `value`. Often chained and terminated with `otherwise()`.                                                                                                                      | `when()` is crucial for creating new categorical features, flagging data, or applying different calculations based on specific conditions. It's a cornerstone of data transformation, enabling dynamic logic.                                                                                                                                                                                           |\n",
        "| `otherwise(value)` | **Used in conjunction with `when()`** to specify the default value if none of the preceding `when()` conditions are met.                                                                                                                                            | `otherwise()` ensures that every row has a value for the new column when using `when()`. Forgetting it can lead to `null` values where you might expect a default. It acts as the `ELSE` clause in a SQL `CASE` statement.                                                                                                                                                                                      |\n",
        "\n",
        "### Examples: Conditional Logic with `when()` and `otherwise()`\n",
        "\n",
        "`when()` and `otherwise()` are powerful for creating new columns based on complex conditions. You can chain multiple `when()` clauses, and the first condition that evaluates to true will have its corresponding value returned.\n",
        "\n",
        "**Setup for Conditional Logic Examples:**"
      ],
      "metadata": {
        "id": "vTzcnBRXwYZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit, expr, when, concat_ws\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CalculatedColumns\").getOrCreate()\n",
        "\n",
        "data_cond = [(\"Alice\", 18, 50000),\n",
        "             (\"Bob\", 25, 60000),\n",
        "             (\"Charlie\", 32, 80000),\n",
        "             (\"David\", 40, 95000),\n",
        "             (\"Eve\", 16, 40000)]\n",
        "columns_cond = [\"Name\", \"Age\", \"Salary\"]\n",
        "df_cond = spark.createDataFrame(data_cond, columns_cond)\n",
        "print(\"Original DataFrame (for conditional logic):\")\n",
        "df_cond.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C8aGB-kwZkD",
        "outputId": "de2c5c35-e671-4eb0-9c84-30182610efc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame (for conditional logic):\n",
            "+-------+---+------+\n",
            "|   Name|Age|Salary|\n",
            "+-------+---+------+\n",
            "|  Alice| 18| 50000|\n",
            "|    Bob| 25| 60000|\n",
            "|Charlie| 32| 80000|\n",
            "|  David| 40| 95000|\n",
            "|    Eve| 16| 40000|\n",
            "+-------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Creating an \"AgeGroup\" Column\n"
      ],
      "metadata": {
        "id": "uF0cKdEYymOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_age_group = df_cond.withColumn(\"AgeGroup\",\n",
        "                                       when(col(\"Age\") < 20, \"Teenager\")\n",
        "                                       .when(col(\"Age\") < 30, \"Young Adult\") # Modified from text for better clarity\n",
        "                                       .otherwise(\"Adult\"))\n",
        "print(\"DataFrame with 'AgeGroup':\")\n",
        "df_with_age_group.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAiBd8iyxvS3",
        "outputId": "01994322-0664-4ea4-c6de-d9f32d82c25f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with 'AgeGroup':\n",
            "+-------+---+------+-----------+\n",
            "|   Name|Age|Salary|   AgeGroup|\n",
            "+-------+---+------+-----------+\n",
            "|  Alice| 18| 50000|   Teenager|\n",
            "|    Bob| 25| 60000|Young Adult|\n",
            "|Charlie| 32| 80000|      Adult|\n",
            "|  David| 40| 95000|      Adult|\n",
            "|    Eve| 16| 40000|   Teenager|\n",
            "+-------+---+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Creating a \"TaxBracket\" Column (with compound conditions)\n"
      ],
      "metadata": {
        "id": "fhNeP5auyrmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_tax_bracket = df_cond.withColumn(\"TaxBracket\",\n",
        "                                       when(col(\"Salary\") < 50000, \"Low\")\n",
        "                                       .when((col(\"Salary\") >= 50000) & (col(\"Salary\") < 80000), \"Medium\")\n",
        "                                       .otherwise(\"High\"))\n",
        "print(\"DataFrame with 'TaxBracket':\")\n",
        "df_with_tax_bracket.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHZhHpKEyovZ",
        "outputId": "8affaf99-af63-4f26-ba27-856c0960381d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with 'TaxBracket':\n",
            "+-------+---+------+----------+\n",
            "|   Name|Age|Salary|TaxBracket|\n",
            "+-------+---+------+----------+\n",
            "|  Alice| 18| 50000|    Medium|\n",
            "|    Bob| 25| 60000|    Medium|\n",
            "|Charlie| 32| 80000|      High|\n",
            "|  David| 40| 95000|      High|\n",
            "|    Eve| 16| 40000|       Low|\n",
            "+-------+---+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nesting Conditions using Multiple `when()` (CASE WHEN equivalent)\n",
        "\n",
        "You can chain multiple `when()` clauses to create complex conditional logic, similar to `CASE WHEN ... THEN ... WHEN ... THEN ... ELSE ... END` in SQL. The conditions are evaluated in order, and the first `when()` condition that evaluates to `true` will have its corresponding value returned.\n",
        "\n",
        "**Setup for Nesting `when()` Examples:**"
      ],
      "metadata": {
        "id": "kgTpXseayxKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_nested = [(\"Alice\", 85),\n",
        "               (\"Bob\", 72),\n",
        "               (\"Charlie\", 91),\n",
        "               (\"David\", 60),\n",
        "               (\"Eve\", 45)]\n",
        "columns_nested = [\"Student\", \"Score\"]\n",
        "df_nested = spark.createDataFrame(data_nested, columns_nested)\n",
        "print(\"Original DataFrame (for nested conditions):\")\n",
        "df_nested.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Caq3HczVyuZD",
        "outputId": "e16bb6f9-b25a-48d3-e3bf-47e10e6d8126"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame (for nested conditions):\n",
            "+-------+-----+\n",
            "|Student|Score|\n",
            "+-------+-----+\n",
            "|  Alice|   85|\n",
            "|    Bob|   72|\n",
            "|Charlie|   91|\n",
            "|  David|   60|\n",
            "|    Eve|   45|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Assigning Grades based on Score\n"
      ],
      "metadata": {
        "id": "2kLRVRT6y2cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_grades = df_nested.withColumn(\"Grade\",\n",
        "                                      when(col(\"Score\") >= 90, \"A\")\n",
        "                                      .when(col(\"Score\") >= 80, \"B\")\n",
        "                                      .when(col(\"Score\") >= 70, \"C\")\n",
        "                                      .when(col(\"Score\") >= 60, \"D\")\n",
        "                                      .otherwise(\"F\")) # Default if no other conditions met\n",
        "print(\"DataFrame with assigned Grades:\")\n",
        "df_with_grades.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnxhM-b8yzpS",
        "outputId": "e7be4735-f607-49b8-913f-36aef67c3690"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with assigned Grades:\n",
            "+-------+-----+-----+\n",
            "|Student|Score|Grade|\n",
            "+-------+-----+-----+\n",
            "|  Alice|   85|    B|\n",
            "|    Bob|   72|    C|\n",
            "|Charlie|   91|    A|\n",
            "|  David|   60|    D|\n",
            "|    Eve|   45|    F|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Complex Scholarship Eligibility Example\n"
      ],
      "metadata": {
        "id": "rLqbpN8Ny7a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_scholarship = df_nested.withColumn(\"ScholarshipStatus\",\n",
        "                                         when((col(\"Score\") >= 90) & (col(\"Student\") == \"Charlie\"), lit(\"Full Scholarship\"))\n",
        "                                         .when(col(\"Score\") >= 85, lit(\"Partial Scholarship\"))\n",
        "                                         .when(col(\"Score\") >= 70, lit(\"Eligibility Review\"))\n",
        "                                         .otherwise(lit(\"Not Eligible\")))\n",
        "print(\"DataFrame with Scholarship Status:\")\n",
        "df_with_scholarship.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxxn5GVOy413",
        "outputId": "00fb566d-7bf0-4ca6-ea03-ed34cff50b80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with Scholarship Status:\n",
            "+-------+-----+-------------------+\n",
            "|Student|Score|  ScholarshipStatus|\n",
            "+-------+-----+-------------------+\n",
            "|  Alice|   85|Partial Scholarship|\n",
            "|    Bob|   72| Eligibility Review|\n",
            "|Charlie|   91|   Full Scholarship|\n",
            "|  David|   60|       Not Eligible|\n",
            "|    Eve|   45|       Not Eligible|\n",
            "+-------+-----+-------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}