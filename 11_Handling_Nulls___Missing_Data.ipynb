{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjli01/PySpark-Notes/blob/main/11_Handling_Nulls___Missing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Nulls in Spark DataFrames for Beginner Data Engineers\n",
        "\n",
        "### 1. Introduction: Why Handle Nulls?\n",
        "\n",
        "Missing data is ubiquitous in real-world datasets. If left unaddressed, nulls can:\n",
        "*   Lead to incorrect analysis and aggregations (e.g., `AVG` calculations might exclude nulls, `COUNT` might treat them differently).\n",
        "*   Cause errors in downstream processing or machine learning models.\n",
        "*   Impact data integrity and quality.\n",
        "\n",
        "Spark offers several methods to effectively manage nulls, allowing you to clean and prepare your data for further processing.\n",
        "\n",
        "### 2. Core `df.na` Methods\n",
        "\n",
        "These methods are accessed through `df.na` (e.g., `my_dataframe.na.fill(...)`).\n",
        "\n",
        "#### a. `na.fill()`: Replacing Null Values\n",
        "\n",
        "*   **Purpose**: Replaces `null` values in specified columns with a given value.\n",
        "*   **Parameters**:\n",
        "    *   `value`: The replacement value. Can be:\n",
        "        *   A single value (e.g., `0`, `\"Unknown\"`) to apply to all compatible columns.\n",
        "        *   A dictionary `{column_name: replacement_value}` to specify different values for different columns.\n",
        "    *   `subset`: (Optional) A list of column names to apply the fill operation to. If `None`, it applies to all columns of compatible type.\n",
        "\n",
        "*   **Key Points**:\n",
        "    *   `value` type must be compatible with the column's data type.\n",
        "    *   Using a dictionary for `value` provides fine-grained control for different column types (e.g., `0` for numeric, `\"N/A\"` for string).\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "U6cpe-ICJeBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"HandlingNulls\").getOrCreate()\n",
        "\n",
        "# Sample Data\n",
        "data = [(\"Alice\", None, \"New York\", 100.0),\n",
        "        (\"Bob\", 25, \"London\", None),\n",
        "        (\"Charlie\", 35, None, 120.5),\n",
        "        (\"David\", None, None, None),\n",
        "        (None, 40, \"Paris\", 90.0),\n",
        "        (\"Eve\", 28, \"Berlin\", 110.0),\n",
        "        (\"Frank\", None, None, None)] # Added for more examples later\n",
        "\n",
        "columns = [\"Name\", \"Age\", \"City\", \"Score\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "df.show()\n",
        "\n",
        "print(\"\\n--- 1. Using na.fill() ---\")\n",
        "\n",
        "# Fill all numeric nulls with 0 and all string nulls in 'City' with \"Unknown\"\n",
        "print(\"\\nAfter filling 'Age' nulls with 0 and 'City' nulls with 'Unknown':\")\n",
        "df.na.fill(0, subset=[\"Age\"]) \\\n",
        "  .na.fill(\"Unknown\", subset=[\"City\"]) \\\n",
        "  .show()\n",
        "\n",
        "# You can also use a dictionary for multiple types/columns in one go\n",
        "print(\"\\nAfter filling 'Age' with 99 and 'City' with 'N/A' using a dictionary:\")\n",
        "fill_values = {\"Age\": 99, \"City\": \"N/A\"}\n",
        "df.na.fill(fill_values).show()\n",
        "\n",
        "# Fill 'Score' nulls with an average (common practice for numeric data)\n",
        "avg_score = df.select(avg(\"Score\")).collect()[0][0] # Calculate average score from non-nulls\n",
        "print(f\"\\nAverage Score for filling: {avg_score}\")\n",
        "\n",
        "df_filled_with_avg = df.na.fill(avg_score, subset=[\"Score\"])\n",
        "print(\"\\nAfter filling 'Score' nulls with calculated average:\")\n",
        "df_filled_with_avg.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEjEGcE5kdbJ",
        "outputId": "8c595ff3-2d5d-4262-eff3-1e1ae273ecbf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "+-------+----+--------+-----+\n",
            "|   Name| Age|    City|Score|\n",
            "+-------+----+--------+-----+\n",
            "|  Alice|NULL|New York|100.0|\n",
            "|    Bob|  25|  London| NULL|\n",
            "|Charlie|  35|    NULL|120.5|\n",
            "|  David|NULL|    NULL| NULL|\n",
            "|   NULL|  40|   Paris| 90.0|\n",
            "|    Eve|  28|  Berlin|110.0|\n",
            "|  Frank|NULL|    NULL| NULL|\n",
            "+-------+----+--------+-----+\n",
            "\n",
            "\n",
            "--- 1. Using na.fill() ---\n",
            "\n",
            "After filling 'Age' nulls with 0 and 'City' nulls with 'Unknown':\n",
            "+-------+---+--------+-----+\n",
            "|   Name|Age|    City|Score|\n",
            "+-------+---+--------+-----+\n",
            "|  Alice|  0|New York|100.0|\n",
            "|    Bob| 25|  London| NULL|\n",
            "|Charlie| 35| Unknown|120.5|\n",
            "|  David|  0| Unknown| NULL|\n",
            "|   NULL| 40|   Paris| 90.0|\n",
            "|    Eve| 28|  Berlin|110.0|\n",
            "|  Frank|  0| Unknown| NULL|\n",
            "+-------+---+--------+-----+\n",
            "\n",
            "\n",
            "After filling 'Age' with 99 and 'City' with 'N/A' using a dictionary:\n",
            "+-------+---+--------+-----+\n",
            "|   Name|Age|    City|Score|\n",
            "+-------+---+--------+-----+\n",
            "|  Alice| 99|New York|100.0|\n",
            "|    Bob| 25|  London| NULL|\n",
            "|Charlie| 35|     N/A|120.5|\n",
            "|  David| 99|     N/A| NULL|\n",
            "|   NULL| 40|   Paris| 90.0|\n",
            "|    Eve| 28|  Berlin|110.0|\n",
            "|  Frank| 99|     N/A| NULL|\n",
            "+-------+---+--------+-----+\n",
            "\n",
            "\n",
            "Average Score for filling: 105.125\n",
            "\n",
            "After filling 'Score' nulls with calculated average:\n",
            "+-------+----+--------+-------+\n",
            "|   Name| Age|    City|  Score|\n",
            "+-------+----+--------+-------+\n",
            "|  Alice|NULL|New York|  100.0|\n",
            "|    Bob|  25|  London|105.125|\n",
            "|Charlie|  35|    NULL|  120.5|\n",
            "|  David|NULL|    NULL|105.125|\n",
            "|   NULL|  40|   Paris|   90.0|\n",
            "|    Eve|  28|  Berlin|  110.0|\n",
            "|  Frank|NULL|    NULL|105.125|\n",
            "+-------+----+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. `na.drop()`: Dropping Rows with Null Values\n",
        "\n",
        "*   **Purpose**: Removes rows from the DataFrame that contain `null` values based on specified conditions.\n",
        "*   **Parameters**:\n",
        "    *   `how`: Specifies the condition for dropping rows.\n",
        "        *   `'any'` (default): Drops a row if it contains *any* `null` values in the considered columns.\n",
        "        *   `'all'`: Drops a row if *all* its values in the considered columns are `null`.\n",
        "    *   `thresh`: (Optional) An integer. Drops a row if it has *fewer than `thresh`* non-null values in the considered columns.\n",
        "    *   `subset`: (Optional) A list of column names to consider for dropping. If `None`, all columns are considered.\n",
        "\n",
        "*   **Key Points**:\n",
        "    *   `na.drop()` is useful for removing incomplete records, but can lead to significant data loss if not used carefully.\n",
        "    *   `thresh` provides a more flexible way to keep partially complete rows.\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "ccZBPz7YXQlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK3n_5_sEAh6",
        "outputId": "295447bc-d36d-44fc-a66f-6e825bb67cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. Using na.drop() ---\n",
            "\n",
            "Original DataFrame:\n",
            "+-------+----+--------+-----+\n",
            "|   Name| Age|    City|Score|\n",
            "+-------+----+--------+-----+\n",
            "|  Alice|NULL|New York|100.0|\n",
            "|    Bob|  25|  London| NULL|\n",
            "|Charlie|  35|    NULL|120.5|\n",
            "|  David|NULL|    NULL| NULL|\n",
            "|   NULL|  40|   Paris| 90.0|\n",
            "|    Eve|  28|  Berlin|110.0|\n",
            "|  Frank|NULL|    NULL| NULL|\n",
            "+-------+----+--------+-----+\n",
            "\n",
            "\n",
            "After dropping rows with ANY null value:\n",
            "+----+---+------+-----+\n",
            "|Name|Age|  City|Score|\n",
            "+----+---+------+-----+\n",
            "| Eve| 28|Berlin|110.0|\n",
            "+----+---+------+-----+\n",
            "\n",
            "\n",
            "After dropping rows where 'Age' OR 'City' is null:\n",
            "+----+---+------+-----+\n",
            "|Name|Age|  City|Score|\n",
            "+----+---+------+-----+\n",
            "| Bob| 25|London| NULL|\n",
            "|NULL| 40| Paris| 90.0|\n",
            "| Eve| 28|Berlin|110.0|\n",
            "+----+---+------+-----+\n",
            "\n",
            "\n",
            "After dropping rows with less than 2 non-null values across ALL columns:\n",
            "+-------+----+--------+-----+\n",
            "|   Name| Age|    City|Score|\n",
            "+-------+----+--------+-----+\n",
            "|  Alice|NULL|New York|100.0|\n",
            "|    Bob|  25|  London| NULL|\n",
            "|Charlie|  35|    NULL|120.5|\n",
            "|   NULL|  40|   Paris| 90.0|\n",
            "|    Eve|  28|  Berlin|110.0|\n",
            "+-------+----+--------+-----+\n",
            "\n",
            "\n",
            "After dropping rows where 'Age' or 'City' has less than 1 non-null value:\n",
            "+-------+----+--------+-----+\n",
            "|   Name| Age|    City|Score|\n",
            "+-------+----+--------+-----+\n",
            "|  Alice|NULL|New York|100.0|\n",
            "|    Bob|  25|  London| NULL|\n",
            "|Charlie|  35|    NULL|120.5|\n",
            "|   NULL|  40|   Paris| 90.0|\n",
            "|    Eve|  28|  Berlin|110.0|\n",
            "+-------+----+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Continue from the previous SparkSession and df\n",
        "\n",
        "print(\"\\n--- 2. Using na.drop() ---\")\n",
        "\n",
        "print(\"\\nOriginal DataFrame:\")\n",
        "df.show() # Showing df again for context\n",
        "\n",
        "# Drop rows if they contain any null value in any column\n",
        "print(\"\\nAfter dropping rows with ANY null value:\")\n",
        "df.na.drop(how='any').show()\n",
        "\n",
        "# Drop rows if 'Age' or 'City' is null\n",
        "print(\"\\nAfter dropping rows where 'Age' OR 'City' is null:\")\n",
        "df.na.drop(subset=[\"Age\", \"City\"]).show()\n",
        "\n",
        "# Drop rows if they have less than 2 non-null values (threshold)\n",
        "print(\"\\nAfter dropping rows with less than 2 non-null values across ALL columns:\")\n",
        "df.na.drop(thresh=2).show()\n",
        "\n",
        "# Drop rows if 'Age' or 'City' has less than 1 non-null value (i.e., if either is null)\n",
        "print(\"\\nAfter dropping rows where 'Age' or 'City' has less than 1 non-null value:\")\n",
        "df.na.drop(thresh=1, subset=[\"Age\", \"City\"]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. `na.replace()`: Replacing Specific Values\n",
        "\n",
        "*   **Purpose**: Replaces specific values (not just `nulls`) in specified columns with another value. This is useful for cleaning up inconsistent data entries like `\"\"`, `\"N/A\"`, or placeholder numbers.\n",
        "*   **Parameters**:\n",
        "    *   `subset`: (Optional) A list of column names to apply the replacement to.\n",
        "    *   `replacement_map`: A dictionary where keys are the values to be replaced, and values are the new replacement values. This can be:\n",
        "        *   `{old_value: new_value}` for a single value replacement.\n",
        "        *   `[{old_value: new_value}, {old_value_2: new_value_2}]` for multiple replacements.\n",
        "        *   For column-specific replacements, it can be `{col_name: {old_value: new_value}}`.\n",
        "\n",
        "*   **Key Points**:\n",
        "    *   Allows for replacing non-null values, unlike `na.fill()`.\n",
        "    *   Handy for standardizing entries or correcting data entry mistakes.\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "x1XjvkFzXROz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue from the previous SparkSession\n",
        "\n",
        "# Sample data for replace\n",
        "df_replace_example = spark.createDataFrame([(\"Apple\", \"Red\"), (\"Banana\", \"Yellow\"),\n",
        "                                            (\"Grape\", \"Red\"), (\"Orange\", \"N/A\")],\n",
        "                                           [\"Fruit\", \"Color\"])\n",
        "print(\"\\n--- 3. Using na.replace() ---\")\n",
        "print(\"\\nOriginal DataFrame for replace example:\")\n",
        "df_replace_example.show()\n",
        "\n",
        "# Replace \"Red\" with \"Crimson\" in the \"Color\" column\n",
        "print(\"\\nAfter replacing 'Red' with 'Crimson' in 'Color' column:\")\n",
        "df_replace_example.na.replace(\"Red\", \"Crimson\", \"Color\").show()\n",
        "\n",
        "# Replace multiple values using a dictionary\n",
        "print(\"\\nAfter replacing 'Red' with 'Crimson' and 'N/A' with 'Unknown' in 'Color':\")\n",
        "replacement_map = {\"Red\": \"Crimson\", \"N/A\": \"Unknown\"}\n",
        "df_replace_example.na.replace(replacement_map, subset=[\"Color\"]).show()\n",
        "\n",
        "# Using the original df, let's replace Age 25 with 100\n",
        "print(\"\\nOriginal DataFrame (again for Age replacement context):\")\n",
        "df.show()\n",
        "print(\"\\nAfter replacing Age 25 with 100:\")\n",
        "df.na.replace(25, 100, \"Age\").show() # Note: The original df has Bob, Age 25."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cXZNmFYXSOi",
        "outputId": "3558bc04-ec06-4a67-9e8a-324f6a30b924"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Using na.replace() ---\n",
            "\n",
            "Original DataFrame for replace example:\n",
            "+------+------+\n",
            "| Fruit| Color|\n",
            "+------+------+\n",
            "| Apple|   Red|\n",
            "|Banana|Yellow|\n",
            "| Grape|   Red|\n",
            "|Orange|   N/A|\n",
            "+------+------+\n",
            "\n",
            "\n",
            "After replacing 'Red' with 'Crimson' in 'Color' column:\n",
            "+------+-------+\n",
            "| Fruit|  Color|\n",
            "+------+-------+\n",
            "| Apple|Crimson|\n",
            "|Banana| Yellow|\n",
            "| Grape|Crimson|\n",
            "|Orange|    N/A|\n",
            "+------+-------+\n",
            "\n",
            "\n",
            "After replacing 'Red' with 'Crimson' and 'N/A' with 'Unknown' in 'Color':\n",
            "+------+-------+\n",
            "| Fruit|  Color|\n",
            "+------+-------+\n",
            "| Apple|Crimson|\n",
            "|Banana| Yellow|\n",
            "| Grape|Crimson|\n",
            "|Orange|Unknown|\n",
            "+------+-------+\n",
            "\n",
            "\n",
            "Original DataFrame (again for Age replacement context):\n",
            "+-------+----+--------+-----+\n",
            "|   Name| Age|    City|Score|\n",
            "+-------+----+--------+-----+\n",
            "|  Alice|NULL|New York|100.0|\n",
            "|    Bob|  25|  London| NULL|\n",
            "|Charlie|  35|    NULL|120.5|\n",
            "|  David|NULL|    NULL| NULL|\n",
            "|   NULL|  40|   Paris| 90.0|\n",
            "|    Eve|  28|  Berlin|110.0|\n",
            "|  Frank|NULL|    NULL| NULL|\n",
            "+-------+----+--------+-----+\n",
            "\n",
            "\n",
            "After replacing Age 25 with 100:\n",
            "+-------+----+--------+-----+\n",
            "|   Name| Age|    City|Score|\n",
            "+-------+----+--------+-----+\n",
            "|  Alice|NULL|New York|100.0|\n",
            "|    Bob| 100|  London| NULL|\n",
            "|Charlie|  35|    NULL|120.5|\n",
            "|  David|NULL|    NULL| NULL|\n",
            "|   NULL|  40|   Paris| 90.0|\n",
            "|    Eve|  28|  Berlin|110.0|\n",
            "|  Frank|NULL|    NULL| NULL|\n",
            "+-------+----+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Advanced Conditional Handling with `when().otherwise()`\n",
        "\n",
        "For more complex null handling logic, especially when you need to derive new values based on conditions involving other columns or intricate rules, `when().otherwise()` from `pyspark.sql.functions` is highly effective.\n",
        "\n",
        "*   **Purpose**: Allows you to create new columns or modify existing ones based on a series of conditions. It's powerful for implementing custom null-filling strategies.\n",
        "*   **Key Concepts**:\n",
        "    *   **`when(condition, value)`**: If `condition` is true, assign `value`.\n",
        "    *   **`.otherwise(value)`**: If none of the preceding `when` conditions are true, assign this `value`.\n",
        "    *   **Chaining**: You can chain multiple `when` clauses (`.when(condition2, value2).when(condition3, value3)...`) for multi-step logic.\n",
        "    *   **`col().isNull()`**: Used to check if a column's value is null.\n",
        "    *   **`lit(value)`**: Used to create a literal value (constant) in Spark expressions.\n",
        "\n",
        "**Example (Python):**"
      ],
      "metadata": {
        "id": "3N6QRdaoXSoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, lit, avg # Added avg for score calculation\n",
        "\n",
        "# Initialize SparkSession (if not already running)\n",
        "# spark = SparkSession.builder.appName(\"ConditionalNullHandling\").getOrCreate()\n",
        "\n",
        "# Sample Data\n",
        "data = [(\"Alice\", 30, \"M\", None),\n",
        "        (\"Bob\", 25, \"M\", 60000),\n",
        "        (\"Charlie\", None, \"F\", 80000), # Age is null\n",
        "        (\"David\", 40, \"M\", None), # Salary is null\n",
        "        (\"Eve\", 22, \"F\", 55000),\n",
        "        (\"Frank\", None, None, None)] # Age, Gender, Salary are null\n",
        "columns = [\"Name\", \"Age\", \"Gender\", \"Salary\"]\n",
        "df_conditional = spark.createDataFrame(data, columns)\n",
        "\n",
        "print(\"\\n--- Conditional Handling with when().otherwise() ---\")\n",
        "print(\"\\nOriginal DataFrame for conditional handling:\")\n",
        "df_conditional.show()\n",
        "\n",
        "# Conditional filling for 'Salary':\n",
        "# - If Salary is null AND Age is less than 30, fill with 50000.\n",
        "# - If Salary is null AND Age is 30 or more, fill with 70000.\n",
        "# - Otherwise, keep original Salary.\n",
        "df_salary_filled = df_conditional.withColumn(\"Salary_Filled\",\n",
        "    when(col(\"Salary\").isNull() & (col(\"Age\") < 30), lit(50000))\n",
        "    .when(col(\"Salary\").isNull() & (col(\"Age\") >= 30), lit(70000))\n",
        "    .otherwise(col(\"Salary\")))\n",
        "\n",
        "print(\"\\nConditional filling for Salary:\")\n",
        "df_salary_filled.show()\n",
        "\n",
        "# Conditional filling for 'Age' and 'Gender' (nested when statements):\n",
        "# - If Age is null:\n",
        "#   - If Gender is 'M', fill Age with 30.\n",
        "#   - If Gender is 'F', fill Age with 28.\n",
        "#   - Otherwise (Gender is also null or unknown), fill Age with 0.\n",
        "# - Otherwise, keep original Age.\n",
        "# For Gender:\n",
        "# - If Gender is null, fill with \"Unknown\".\n",
        "# - Otherwise, keep original Gender.\n",
        "\n",
        "df_age_gender_filled = df_conditional.withColumn(\"Age_Filled\",\n",
        "    when(col(\"Age\").isNull(), # Outer condition: if Age is null\n",
        "        when(col(\"Gender\") == \"M\", lit(30)) # Inner condition 1: if Gender is M\n",
        "        .when(col(\"Gender\") == \"F\", lit(28)) # Inner condition 2: if Gender is F\n",
        "        .otherwise(lit(0)) # Default if Gender is also null or neither M/F\n",
        "    )\n",
        "    .otherwise(col(\"Age\")) # If Age is not null, keep original Age\n",
        ").withColumn(\"Gender_Filled\",\n",
        "    when(col(\"Gender\").isNull(), lit(\"Unknown\"))\n",
        "    .otherwise(col(\"Gender\"))\n",
        ")\n",
        "\n",
        "print(\"\\nConditional filling for Age and Gender:\")\n",
        "df_age_gender_filled.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmnRcSwmXS9Z",
        "outputId": "c83b47b3-3125-4d06-f8fa-a24026deaccd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Conditional Handling with when().otherwise() ---\n",
            "\n",
            "Original DataFrame for conditional handling:\n",
            "+-------+----+------+------+\n",
            "|   Name| Age|Gender|Salary|\n",
            "+-------+----+------+------+\n",
            "|  Alice|  30|     M|  NULL|\n",
            "|    Bob|  25|     M| 60000|\n",
            "|Charlie|NULL|     F| 80000|\n",
            "|  David|  40|     M|  NULL|\n",
            "|    Eve|  22|     F| 55000|\n",
            "|  Frank|NULL|  NULL|  NULL|\n",
            "+-------+----+------+------+\n",
            "\n",
            "\n",
            "Conditional filling for Salary:\n",
            "+-------+----+------+------+-------------+\n",
            "|   Name| Age|Gender|Salary|Salary_Filled|\n",
            "+-------+----+------+------+-------------+\n",
            "|  Alice|  30|     M|  NULL|        70000|\n",
            "|    Bob|  25|     M| 60000|        60000|\n",
            "|Charlie|NULL|     F| 80000|        80000|\n",
            "|  David|  40|     M|  NULL|        70000|\n",
            "|    Eve|  22|     F| 55000|        55000|\n",
            "|  Frank|NULL|  NULL|  NULL|         NULL|\n",
            "+-------+----+------+------+-------------+\n",
            "\n",
            "\n",
            "Conditional filling for Age and Gender:\n",
            "+-------+----+------+------+----------+-------------+\n",
            "|   Name| Age|Gender|Salary|Age_Filled|Gender_Filled|\n",
            "+-------+----+------+------+----------+-------------+\n",
            "|  Alice|  30|     M|  NULL|        30|            M|\n",
            "|    Bob|  25|     M| 60000|        25|            M|\n",
            "|Charlie|NULL|     F| 80000|        28|            F|\n",
            "|  David|  40|     M|  NULL|        40|            M|\n",
            "|    Eve|  22|     F| 55000|        22|            F|\n",
            "|  Frank|NULL|  NULL|  NULL|         0|      Unknown|\n",
            "+-------+----+------+------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary and Best Practices\n",
        "\n",
        "*   **`na.fill()`**: Best for simple, direct replacements of nulls with a constant value (numeric, string, etc.) or a dictionary of column-specific values.\n",
        "*   **`na.drop()`**: Use when incomplete rows are undesirable or when a large percentage of nulls makes a record useless. Be cautious of data loss.\n",
        "*   **`na.replace()`**: Ideal for standardizing non-null values, fixing data entry errors, or handling specific placeholder values that aren't technically `null`.\n",
        "*   **`when().otherwise()`**: The most flexible method for complex, rule-based null handling, conditional logic across columns, or deriving new values. It's often used when simple `fill` or `drop` isn't sufficient.\n",
        "\n",
        "Always understand your data and the implications of your null-handling strategy. Incorrect handling can lead to biased analyses or data loss."
      ],
      "metadata": {
        "id": "NLTwUwDHXTQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "7H0UVkuJXTgE"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}